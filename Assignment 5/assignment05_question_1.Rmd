---
title: "Assignment 05, Question 1"
author: "Jeff Nguyen"
date: "24/04/2021"
output:
  pdf_document: default
  html_document:
    code_folding: "hide"
---
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```

**University of Southern California**  
**Marshall School of Business**  
**FBE 543 Forecasting and Risk Analysis**

#**Question 1**  


```{r}
library(quantmod)

# Set start date and end date of data
start_date <- "2014-01-01"
end_date <- "2021-03-23"

# Get data
getSymbols("JPM", src = "yahoo", , from = start_date, to = end_date) 

adjJPM_mo <- to.monthly(JPM)$JPM.Adjusted  # Monthly Adjusted Closing Price
rJPM_mo <- diff(log(adjJPM_mo))[-1]  # Monthly Returns

```
  
## Data Observation:  

Observing monthly adjusted closing prices:  
```{r}
library(forecast)

ggtsdisplay(adjJPM_mo, main="JP Morgan Monthly Adj. Close Price", plot.type="scatter")
```
  
Observing monthly returns:  
```{r}
ggtsdisplay(rJPM_mo, main="JP Morgan Monthly Returns", plot.type="scatter")
```
  
**Remarks**  
We can see JPM's monthly adjusted closing price' lag plots exhibit a linear pattern, implying that the data is strongly non-random and thus, a first-order autoregressive model might be appropriate.  
  
\begin{equation}
  \begin{aligned}
    y_t =& \beta_0 + \beta_1 y_{t-1} + \epsilon_t
  \end{aligned}
\end{equation}
  
On the other hand, JPM's monthly returns's lag plot does not exhibit any obvious patterns, implying that the data is strongly random. 

  
## 1. Test for the stationarity of the adjusted closing prices for JPM.  
  
We run Augmented Dickey Fuller Test for JPM. Recall that the null hypothesis for Dickey-Fuller Test is that a unit root is present in our autoregressive model, meaning the variable is a non-stationary variable.  
  
```{r}
library(aTSA)

adf.test(adjJPM_mo)
```
  
We can observe $p-value = .99 > .05$. Thus, we fail to reject the null hypothesis. In other words, JPM monthly adjusted closing price has a unit root and therefore, is a non-stationary variable.
  
## 2. Test for the stationarity of the returns for JPM.  

Similarly, we run (A)DF test for JPM's monthly returns:  
  
```{r}
adf.test(rJPM_mo)
```
  
We can observe $p-value = .99 > .05$. Thus, we fail to reject the null hypothesis. In other words, JPM monthly returns has a unit root and therefore, is a non-stationary variable.
  
## 3. Run the best ARIMA model for JPM returns.  
  
We run auto ARIMA:

```{r}
model1ARIMA <- auto.arima(rJPM_mo)
summary(model1ARIMA)
```
  
We can observe that ARIM(0,0,0) model with non-zero mean represents a White Noise model with independent and identically distributed data.
  
## 4. Test for the existence of heteroskedasticity on the residuals of the JPM’s ARIMA model.  

```{r}
residuals_model1ARIMA <- model1ARIMA$residuals
plot(residuals_model1ARIMA, main="Plot of Residuals")

residualsSq_model1ARIMA <- residuals_model1ARIMA^2
```
  
Testing for hetereoscedacity on the residuals of the ARIMA model above using Breusch-Pagan Test: 
  
```{r}
library(lmtest)

reg_residualsSq_model1ARIMA <- lm(residualsSq_model1ARIMA ~ rJPM_mo)
bp_residualsSq_model1ARIMA <- bptest(reg_residualsSq_model1ARIMA)

bp_residualsSq_model1ARIMA
```
  
We can observe $p-value=.01343 < .05$, thus we reject the null-hypothesis and assume hetereoscedacity of the residuals of the ARIMA model for monthly JPM stock returns.  
  
Similarly, we attempt a Goldfield-Quant test:  

```{r}
gq_residualsSq_model1ARIMA <- gqtest(reg_residualsSq_model1ARIMA)
gq_residualsSq_model1ARIMA
```
  
We can observe similar result with the Breusch-Pagan test as $p-value = 1.308e-07 < .05$, i.e. we reject the null hypothesis and assume hetereoscedacity for the residuals of the ARIMA model for monthly returns.
  
## 5. Find the historical measure of the volatility of the JPM’s returns.  
  
Recall the historical volatility measure:  

\begin{equation}
  \begin{split}
    \sigma^2_{hist} =& \frac{\sum (r - \overline{r})^2}{n-1}   \\
    \text{where} \, r =& \, \text{monthly stock returns}  \\
    n =& \, \text{number of observations}   \\
  \end{split}
\end{equation}

```{r}
mean_rJPM_mo <- mean(rJPM_mo)
sigmaSq_hist <- sum((rJPM_mo - mean_rJPM_mo)^2 / (length(rJPM_mo) - 1))
sigmaSq_hist
```
  
Thus, $\sigma^2_{hist} = `r sigmaSq_hist`$.
  
## 6. Find the Exponentially Weighted Moving Average (EWMA) measure of the volatility of JPM’s returns.  
  
The EWMA measure of volatility is the exponential smoothing of the square of JPM's monthly returns. We have:  

```{r}
rJPM_mo_Sq <- rJPM_mo^2

#Simple Exponential Smoothing
fit1 <- ses(rJPM_mo_Sq, alpha=0.2, initial="simple", h=3)
fit2 <- ses(rJPM_mo_Sq, alpha=0.6, initial="simple", h=3)
fit3 <- ses(rJPM_mo_Sq, h=3)
plot(fit1, main="Simple Exponential Smoothing, Monthly JPM Returns", fcol="white", type="o")
lines(fitted(fit1), col="blue", type="o")
lines(fitted(fit2), col="red", type="o")
lines(fitted(fit3), col="green", type="o")
lines(fit1$mean, col="blue", type="o")
lines(fit2$mean, col="red", type="o")
lines(fit3$mean, col="green", type="o")
legend("topleft",lty=1, col=c(1,"blue","red","green"), 
       c("data", expression(alpha == 0.2), expression(alpha == 0.6),
         expression(alpha == 0.89)),pch=1)
```
  
Recall:

\begin{equation}
  \begin{split}
    \sigma^2_{EWMA} =& (1 - \lambda) \sum \lambda (r - \overline{r})^2  \\
    \text{where} \, \lambda =& .94  \\
  \end{split}
\end{equation}

```{r}
lambda <- .94
sigmaSq_EWMA <- (1-lambda) * sum(lambda * (rJPM_mo - mean_rJPM_mo)^2)
sigmaSq_EWMA
```
  
We can see that $\sigma^2_{EWMA} = `r sigmaSq_EWMA`$.

## 7. Test whether the two measures of the volatility, historical and EWMA, are statistically the same.  

We can see that $\sigma^2_{hist} = `r sigmaSq_hist` \neq `r sigmaSq_EWMA` = \sigma^2_{EWMA}$. Thus, they are not the same.  
  
## 8. Estimate an auto-regression model of the volatility for JPM’s returns using r^2 and log(High/low) as measures of volatility. Use the model to forecast next three-periods conditional variance.  
  
### Estimating ARIMA model of JPM's monthly returns volatility using r^2  

```{r}
fit4 <- auto.arima(rJPM_mo_Sq)
fit4
```
  
We can see the model is again, a White Noise model. Forecasting the next three periods:  

```{r}
fcast4 <-forecast::forecast(fit4, h=3)
fcast4
plot(fcast4)
```
  
### Estimating ARIMA model of JPM's monthly returns volatility using $\ln{H/L}$  
  
```{r}
lnJPM_HL <- log(to.monthly(JPM)$JPM.High/to.monthly(JPM)$JPM.Low)[-1]

fit5 <- auto.arima(lnJPM_HL)
fit5

fcast5 <-forecast::forecast(fit5, h=3)
fcast5
plot(fcast5)
```
  

## 11. Run an ARCH and/or GARCH model on JPM’s returns data.  
  
```{r}
library(rugarch)

# Write Specification of Your GARCH Model using "sGrach" or standard GARCH Mode.
garch1 <- ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(1, 1)), mean.model=list(armaOrder=c(1, 1)), distribution.model="std")

# Fit the Model to Data
garch1_rJPM_mo <- ugarchfit(spec=garch1, data=rJPM_mo)
garch1_rJPM_mo
```
  
## 12. Do a three-period ahead forecast of the conditional variance.  
```{r}
# Forecast Model
predict_rJPM_mo <- ugarchboot(garch1_rJPM_mo,n.ahead=3, method=c("Partial", "Full")[1])
plot(predict_rJPM_mo, which=2)
```